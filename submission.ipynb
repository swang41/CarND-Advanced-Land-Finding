{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as impg\n",
    "from collections import deque\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predefine class and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a class to receive the characteristics of each line detection\n",
    "\n",
    "class Line():\n",
    "    def __init__(self, n):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = deque(maxlen = n)\n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None     \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]  \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        #x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None\n",
    "        #distance between the lane and left of image\n",
    "        self.lane_x_zero = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calibrate_camera(images, nx = 9, ny = 6):\n",
    "    '''\n",
    "    Find require parameters to calibrate camera with chessboard images\n",
    "    param: \n",
    "        images: recommending at least 20 images\n",
    "        nx: number of corners each row\n",
    "        ny: number of corners each column\n",
    "    return:\n",
    "        mtx: camera matrix\n",
    "        dist: distortion coeficients\n",
    "    '''\n",
    "    objp = np.zeros((ny * nx, 3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1, 2)\n",
    "    \n",
    "    objpoints = []\n",
    "    imgpoints = []\n",
    "    for img_path in camera_cal_img_paths:\n",
    "        img = plt.imread(img_path)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "        if ret:\n",
    "            img = cv2.drawChessboardCorners(img, (nx, ny), corners, ret)\n",
    "            #plt.imshow(img)\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "            \n",
    "    # camera calibration\n",
    "    ret, mtx, dist, rvess, tvess = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "    return (mtx, dist)\n",
    "\n",
    "\n",
    "def threshold_sx_s(image, thres_scheme = 1, s_thres = [120, 255], r_thres = [180,255], g_thres = [200,255],\n",
    "                  l_thres_shadow = [0, 155], l_thres = [155, 255], sx_thres = [20, 100]):\n",
    "    '''\n",
    "    Saturation and gradient of lightness on x direction thresholding the image and generate a binary image\n",
    "    param:\n",
    "        image: a image, require color space is RGB\n",
    "        sx_thres: a list, [lower_bound, higher_bound] threshold for scaled sobel x\n",
    "        s_thres: a list, [lower_bound, higher_bound] threshold for saturation channel\n",
    "    return:\n",
    "        a binary image after applying both thresholding \n",
    "    '''\n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    l_channel = hls[:, :, 1]\n",
    "    s_channel = hls[:, :, 2]\n",
    "    r_channel = image[:, :, 0]\n",
    "    g_channel = image[:, :, 1]\n",
    "    \n",
    "    if thres_scheme == 0:\n",
    "        sobelx = cv2.Sobel(l_channel, cv2.CV_64F, 1, 0)\n",
    "        abs_sobelx = np.absolute(sobelx)\n",
    "        scaled_sobel = np.uint8(255 * abs_sobelx / np.max(abs_sobelx))\n",
    "        sxbinary = np.zeros_like(l_channel)\n",
    "        sxbinary[(scaled_sobel >= sx_thres[0]) & (scaled_sobel < sx_thres[1])] = 1\n",
    "        \n",
    "        region_interest = np.ones_like(l_channel)\n",
    "        region_interest[480:, 500:700] = 0\n",
    "        \n",
    "        combined = np.zeros_like(l_channel)\n",
    "        combined[(sxbinary == 1) & region_interest == 1] = 1\n",
    "        return combined\n",
    "\n",
    "    else:\n",
    "        r_binary = np.zeros_like(l_channel)\n",
    "        r_binary[(r_channel >= r_thres[0]) & (r_channel < r_thres[1])] = 1\n",
    "\n",
    "        g_binary = np.zeros_like(l_channel)\n",
    "        g_binary[(g_channel >= g_thres[0]) & (g_channel < g_thres[1])] = 1\n",
    "\n",
    "        s_binary = np.zeros_like(l_channel)\n",
    "        s_binary[(s_channel >= s_thres[0]) & (s_channel < s_thres[1])] = 1\n",
    "    \n",
    "        l_binary_shadow = np.zeros_like(l_channel)\n",
    "        l_binary_shadow[(l_channel >= l_thres_shadow[0]) & (l_channel < l_thres_shadow[1])] = 1\n",
    "\n",
    "        l_binary = np.zeros_like(l_channel)\n",
    "        l_binary[(l_channel >= l_thres[0]) & (l_channel < l_thres[1])] = 1\n",
    "\n",
    "\n",
    "        combined_binary = np.zeros_like(l_channel)\n",
    "        combined_binary[( ( (s_binary == 1) & (l_binary == 1) ) |\n",
    "                      ( (r_binary == 1) & (l_binary_shadow == 1) ) |\n",
    "                      (g_binary == 1) )] = 1\n",
    "        return combined_binary\n",
    "\n",
    "\n",
    "def perspective_transform(src, dest):\n",
    "    '''\n",
    "    Find both transform matrix and inverse transform matrix with provided srt and dest\n",
    "    '''\n",
    "    M = cv2.getPerspectiveTransform(src, dest)\n",
    "    M_inv = cv2.getPerspectiveTransform(dest, src)\n",
    "    return (M, M_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def blind_search(side, binary_warped, undist, nwindows = 9, margin = 100, minpix = 50):\n",
    "    '''\n",
    "        blind search for active pixel for the specified lane, if cannot find enough pixel, try another\n",
    "        thresholding scheme which will only use sobel on x direction\n",
    "    '''\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    if side == 'left':\n",
    "        left_lane.current_fit = None\n",
    "        x_base = np.argmax(histogram[:midpoint])\n",
    "    else:\n",
    "        right_lane.current_fit = None\n",
    "        x_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Set height of windows\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    x_current = x_base\n",
    "    \n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_x_low = x_current - margin\n",
    "        win_x_high = x_current + margin\n",
    " \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_x_low) &  (nonzerox < win_x_high)).nonzero()[0]\n",
    "\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        lane_inds.append(good_inds)\n",
    "        \n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_inds) > minpix:\n",
    "            x_current = np.int(np.mean(nonzerox[good_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    lane_inds = np.concatenate(lane_inds)\n",
    "    \n",
    "    # Extract left and right line pixel positions\n",
    "    x = nonzerox[lane_inds]\n",
    "    y = nonzeroy[lane_inds] \n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    if len(x) > 50:\n",
    "        fit = np.polyfit(y, x, 2)\n",
    "    \n",
    "        if side == 'left':\n",
    "            left_lane.allx = x\n",
    "            left_lane.ally = y\n",
    "            left_lane.current_fit = fit\n",
    "        else:\n",
    "            right_lane.allx = x\n",
    "            right_lane.ally = y\n",
    "            right_lane.current_fit = fit\n",
    "    else:\n",
    "        warped = threshold_sx_s(undist, 0)\n",
    "        findLanes(warped, undist)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def margin_search(side, binary_warped, undist, nwindows = 9, margin = 100, minpix = 50):\n",
    "    '''\n",
    "        searching for pixels around the averaged fitted line within certain margin\n",
    "        Params:\n",
    "            side:          str, indicates 'left' or 'right'\n",
    "            binary_warped: np.array, binary value of target image\n",
    "            undist:        np.array, target image\n",
    "            nwindows:      int, number of windows vertically need to search\n",
    "            margin:        int, margin of best fit line set to find active pixel\n",
    "            minpix:        int, minimun number of existing pixel need to update the current centeriod\n",
    "    '''\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    " \n",
    "    if side == 'left':\n",
    "        fit = left_lane.best_fit\n",
    "    else:\n",
    "        fit = right_lane.best_fit\n",
    "        \n",
    "    lane_inds = ((nonzerox > (fit[0]*(nonzeroy**2) + fit[1]*nonzeroy + \n",
    "    fit[2] - margin)) & (nonzerox < (fit[0]*(nonzeroy**2) + \n",
    "    fit[1]*nonzeroy + fit[2] + margin))) \n",
    "\n",
    "    # Again, extract left and right line pixel positions\n",
    "    x = nonzerox[lane_inds]\n",
    "    y = nonzeroy[lane_inds] \n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    if len(x) > 50:\n",
    "        fit = np.polyfit(y, x, 2)\n",
    "        if side == 'left':\n",
    "            left_lane.allx = x\n",
    "            left_lane.ally = y\n",
    "            left_lane.current_fit = fit\n",
    "        else:\n",
    "            right_lane.allx = x\n",
    "            right_lane.ally = y\n",
    "            right_lane.current_fit = fit\n",
    "    else:\n",
    "        blind_search(side, binary_warped, undist, nwindows, margin, minpix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findLanes(binary_warped, undist, nwindows = 9, margin = 100, minpix = 50):\n",
    "    '''\n",
    "        Find lanes with margin search if lane was detected in previous frame, otherwise use blind search,\n",
    "        If lanes found don't seem to parallel and margin search was used, try blind search instead.  \n",
    "        don't quiet parallel with each other use last n averaged fitted lane.\n",
    "        Params:\n",
    "            binary_warped: np.array, binary value of target image\n",
    "            undist:        np.array, target image\n",
    "            nwindows:      int, number of windows vertically need to search\n",
    "            margin:        int, margin of best fit line set to find active pixel\n",
    "            minpix:        int, minimun number of existing pixel need to update the current centeriod\n",
    "    '''\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    which_test_left = 'blind'\n",
    "    which_test_right = 'blind'\n",
    "    \n",
    "    if left_lane.detected:\n",
    "        margin_search('left', binary_warped, undist, nwindows, margin, minpix)\n",
    "        which_test_left = 'margin'\n",
    "    else:\n",
    "        blind_search('left', binary_warped, undist, nwindows, margin, minpix)\n",
    "    \n",
    "    if right_lane.detected:\n",
    "        margin_search('right', binary_warped, undist, nwindows, margin, minpix)\n",
    "        which_test_right = 'margin'\n",
    "    else:\n",
    "        blind_search('right', binary_warped, undist, nwindows, margin, minpix)\n",
    "    \n",
    "        \n",
    "    if which_test_left != 'blind' or which_test_right != 'blind':\n",
    "        coef_diff = left_lane.current_fit[:-1] - right_lane.current_fit[:-1]\n",
    "        left_coef_norm = np.linalg.norm(left_lane.current_fit[:-1], 2)\n",
    "        right_coef_norm = np.linalg.norm(right_lane.current_fit[:-1], 2)\n",
    "        diff_norm = np.linalg.norm(coef_diff,2) / (left_coef_norm + right_coef_norm)\n",
    "        coefs_diff_norm.append(diff_norm)\n",
    "        if diff_norm > 0.1:\n",
    "            if which_test_left != 'blind':\n",
    "                blind_search('left', binary_warped, undist, nwindows, margin, minpix)\n",
    "            if which_test_right != 'blind':\n",
    "                blind_search('right', binary_warped, undist, nwindows, margin, minpix)\n",
    "     \n",
    "    \n",
    "    coef_diff = left_lane.current_fit[:-1] - right_lane.current_fit[:-1]\n",
    "    left_coef_norm = np.linalg.norm(left_lane.current_fit[:-1], 2)\n",
    "    right_coef_norm = np.linalg.norm(right_lane.current_fit[:-1], 2)\n",
    "    diff_norm = np.linalg.norm(coef_diff,2) / (left_coef_norm + right_coef_norm)\n",
    "    coefs_diff_norm_blind.append(diff_norm)   \n",
    "    \n",
    "    \n",
    "    if diff_norm < ACCEPTED_THRES:\n",
    "        left_lane.recent_xfitted.append( left_lane.current_fit[0]*ploty**2 +\n",
    "                                        left_lane.current_fit[1]*ploty +\n",
    "                                        left_lane.current_fit[2] )\n",
    "        left_lane.bestx = np.mean(np.array(list(left_lane.recent_xfitted)), axis = 0)\n",
    "        left_lane.best_fit = np.polyfit(ploty, left_lane.bestx, 2)\n",
    "        left_lane.detected = True\n",
    "        right_lane.recent_xfitted.append( right_lane.current_fit[0]*ploty**2 +\n",
    "                                         right_lane.current_fit[1]*ploty +\n",
    "                                         right_lane.current_fit[2] )\n",
    "        right_lane.bestx = np.mean(np.array(list(right_lane.recent_xfitted)), axis = 0)\n",
    "        right_lane.best_fit = np.polyfit(ploty, right_lane.bestx, 2)\n",
    "        right_lane.detected = True\n",
    "        \n",
    "    elif diff_norm > SMOOTH_THRES and left_lane.best_fit is not None and right_lane.best_fit is not None:\n",
    "        left_lane.current_fit = left_lane.best_fit\n",
    "        left_lane.allx = left_lane.bestx\n",
    "        left_lane.ally = ploty\n",
    "        left_lane.detected = False\n",
    "        right_lane.current_fit = right_lane.best_fit\n",
    "        right_lane.allx = right_lane.bestx\n",
    "        right_lane.ally = ploty\n",
    "        right_lane.detected = False\n",
    "        \n",
    "    coef_diff = left_lane.current_fit[:-1] - right_lane.current_fit[:-1]\n",
    "    left_coef_norm = np.linalg.norm(left_lane.current_fit[:-1], 2)\n",
    "    right_coef_norm = np.linalg.norm(right_lane.current_fit[:-1], 2)\n",
    "    diff_norm = np.linalg.norm(coef_diff,2) / (left_coef_norm + right_coef_norm)\n",
    "    coefs_diff_norm_smooth.append(diff_norm)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def projectLane(image, M_inv):\n",
    "    \n",
    "    left_fit = left_lane.current_fit\n",
    "    right_fit = right_lane.current_fit\n",
    "    \n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(image[:,:,0]).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, image.shape[0]-1, image.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, M_inv, (image.shape[1], image.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(image, 1, newwarp, 0.3, 0)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_curvature(side, y_eval, h = 20, ym_per_pix = 30/720, xm_per_pix = 3.7/800):\n",
    "    \n",
    "    if side == 'left':\n",
    "        x, y = left_lane.allx, left_lane.ally\n",
    "    else:\n",
    "        x, y = right_lane.allx, right_lane.ally\n",
    "        \n",
    "    # Fit new polynomials to x,y in world space\n",
    "    fit_cr = np.polyfit(y*ym_per_pix, x*xm_per_pix, 2)\n",
    "    \n",
    "    # Calculate the new radii of curvature\n",
    "    curverad = ((1 + (2*fit_cr[0]*y_eval*ym_per_pix + fit_cr[1])**2)**1.5) / np.absolute(2*fit_cr[0])\n",
    "    \n",
    "    # Now our radius of curvature is in meters\n",
    "    lane_x_zero = fit_cr[0] * h**2 + fit_cr[1] * h + fit_cr[2]\n",
    "    \n",
    "    if side == 'left':\n",
    "        left_lane.lane_x_zero = lane_x_zero\n",
    "        left_lane.radius_of_curvature = curverad\n",
    "    else:\n",
    "        right_lane.lane_x_zero = lane_x_zero\n",
    "        right_lane.radius_of_curvature = curverad\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_desc(new_image, num_pix_x, xm_per_pix = 3.7/800):\n",
    "    \n",
    "    lane_center = (right_lane.lane_x_zero - left_lane.lane_x_zero)\n",
    "    vehicle_center = (num_pix_x * xm_per_pix) / 2\n",
    "    \n",
    "    to_left = lane_center - vehicle_center\n",
    "    text1 = 'Radius of curvature: {0:.0f}(m)'.format(\n",
    "    (left_lane.radius_of_curvature + right_lane.radius_of_curvature) / 2)\n",
    "    \n",
    "    side_text = 'left' if to_left > 0 else 'right'\n",
    "    \n",
    "    text2 = 'Vehicle is {:.3f} m {} to the center'.format(abs(to_left), side_text)\n",
    "    result = new_image.copy()\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(result, text1, (100,100), font, 1, (255,255,255),2, cv2.LINE_AA)\n",
    "    cv2.putText(result, text2, (100,150), font, 1,(255,255,255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    images.append(image)\n",
    "    undist = cv2.undistort(image,\n",
    "                           mtx,\n",
    "                           dst,\n",
    "                           None, \n",
    "                           mtx)\n",
    "    binary_warped = threshold_sx_s(undist)\n",
    "    warped = cv2.warpPerspective(binary_warped, \n",
    "                                 M, \n",
    "                                 binary_warped.shape[::-1], \n",
    "                                 flags = cv2.INTER_LINEAR)\n",
    "    \n",
    "    findLanes(warped, undist)\n",
    "\n",
    "    new_image= projectLane(undist, \n",
    "                           M_inv)\n",
    "    \n",
    "    cal_curvature('left', new_image.shape[0])\n",
    "    cal_curvature('right', new_image.shape[0])\n",
    "    \n",
    "    new_image = add_desc(new_image, new_image.shape[1])\n",
    "    \n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Calibrate camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "camera_cal_img_paths = list(map(lambda path: './camera_cal/' + path.split('\\\\')[-1] ,\n",
    "                     glob.glob('./camera_cal/*.jpg')))\n",
    "camera_cal_imgs = [plt.imread(img_path) for img_path in camera_cal_img_paths]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_img_paths = list(map(lambda path: './test_images/' + path.split('\\\\')[-1],\n",
    "                          glob.glob('./test_images/*.jpg')))\n",
    "test_imgs = [plt.imread(img_path) for img_path in test_img_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mtx, dst = calibrate_camera(camera_cal_imgs, 9, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Run pipeline on the project Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src = np.float32([[570, 467],\n",
    "                  [206, 720], \n",
    "                  [715, 467],\n",
    "                  [1100, 720]])\n",
    "dest = np.float32([[325, 200],\n",
    "                   [325, 720],\n",
    "                   [968, 200],\n",
    "                   [968, 720]])\n",
    "\n",
    "M, M_inv = perspective_transform(src, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clip = VideoFileClip(\"./project_video.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_last_n_frame = 10\n",
    "ACCEPTED_THRES= 0.5\n",
    "SMOOTH_THRES = 0.7\n",
    "left_lane = Line(keep_last_n_frame)\n",
    "right_lane = Line(keep_last_n_frame)\n",
    "coefs_diff_norm = []\n",
    "coefs_diff_norm_blind = []\n",
    "coefs_diff_norm_smooth = []\n",
    "images = []\n",
    "out_clip = clip.fl_image(process_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video ./out_clip.mp4\n",
      "[MoviePy] Writing video ./out_clip.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████▉| 1260/1261 [01:40<00:00, 12.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./out_clip.mp4 \n",
      "\n",
      "Wall time: 1min 40s\n"
     ]
    }
   ],
   "source": [
    "output = './out_clip.mp4'\n",
    "%time out_clip.write_videofile(output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"./out_clip.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Run pipeline on the challenge Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src = np.float32([[570, 467],\n",
    "                  [206, 720], \n",
    "                  [715, 467],\n",
    "                  [1100, 720]])\n",
    "dest = np.float32([[325, 200],\n",
    "                   [325, 720],\n",
    "                   [968, 200],\n",
    "                   [968, 720]])\n",
    "\n",
    "M, M_inv = perspective_transform(src, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "challenge_clip = VideoFileClip(\"./challenge_video.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_last_n_frame = 25\n",
    "ACCEPTED_THRES= 0.5\n",
    "SMOOTH_THRES = 0.5\n",
    "left_lane = Line(keep_last_n_frame)\n",
    "right_lane = Line(keep_last_n_frame)\n",
    "coefs_diff_norm = []\n",
    "coefs_diff_norm_blind = []\n",
    "coefs_diff_norm_smooth = []\n",
    "images = []\n",
    "out_clip = challenge_clip.fl_image(process_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video ./challenge_out_clip.mp4\n",
      "[MoviePy] Writing video ./challenge_out_clip.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 485/485 [00:36<00:00, 14.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./challenge_out_clip.mp4 \n",
      "\n",
      "Wall time: 37.3 s\n"
     ]
    }
   ],
   "source": [
    "output = './challenge_out_clip.mp4'\n",
    "%time out_clip.write_videofile(output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"./challenge_out_clip.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
